#!/bin/bash

# Results directory
RESULTS_DIR=$1
# AWS Bucket to store results
AWS_BUCKET=$2

# Maximum number of cores to use
MAX_CORES=27

# STAGGER_TIME in seconds. To avoid mass dumping to disk simultaneously. 
STAGGER_TIME=100

# Experiment settings
# MCMC_ITER=1000
# BURN=20000
MCMC_ITER=6000
BURN=3000
# K_MCMC="15"
# K_MCMC="`seq -w 2 20 | shuf`"
# K_MCMC="`seq -w 2 2 50 | shuf`"
K_MCMC="30"
# DNOISY="cauchy normal"
# NOISY_SCALE="0.0316 0.071 0.1"
DNOISY="normal"
NOISY_SCALE="3.16"
# L0_MCMC="10"
# L1_MCMC="5"
# L0_MCMC="5"
# L1_MCMC="3"
L0_MCMC="2"
L1_MCMC="2"
TAU0="10.0"
TAU1="10.0"
DATA_PATH="data/cytof_cb_with_nan.jld2"
SEED=0
SUBSAMPLE="0.05"
isTest=""
otherFlags=""
SMARTINIT="true"

if [[ $@ == **--test** ]]
then
  echo "Testing with small numbers..."
  # STAGGER_TIME in seconds. To avoid mass dumping to disk simultaneously. 
  STAGGER_TIME=0

  # Experiment settings
  MCMC_ITER=50
  BURN=100
  K_MCMC=5
  SUBSAMPLE="0.01"
  isTest="_isTest"
fi

if [[ $@ == **--testlocal** ]]
then
  echo "Testing with subsample locally..."
  # STAGGER_TIME in seconds. To avoid mass dumping to disk simultaneously. 
  STAGGER_TIME=0

  # Experiment settings
  MCMC_ITER=1000
  BURN=1000
  K_MCMC=15
  SUBSAMPLE="0.05"
  isTest="_isTest"
fi

if [[ $@ == **--testplots** ]]
then
  echo "Testing with subsample locally..."
  # STAGGER_TIME in seconds. To avoid mass dumping to disk simultaneously. 
  STAGGER_TIME=0

  # Experiment settings
  MCMC_ITER=100
  BURN=100
  K_MCMC=5
  SUBSAMPLE="0.1"
  isTest="_isTest"
  SMARTINIT="true"
fi

# simulation number, just for book keeping. Ignore this.
simNumber=0

for smartinit in $SMARTINIT; do
  for k_mcmc in $K_MCMC; do
    for dnoisy in $DNOISY; do
      for noisy_scale in $NOISY_SCALE; do
        # Simulation number
        simNumber=$((simNumber + 1)) 

        # Experiment name
        exp_name="K_MCMC${k_mcmc}_L0_MCMC${L0_MCMC}_L1_MCMC${L1_MCMC}_tau0_${TAU0}_tau1_${TAU1}_SEED${SEED}_smartinit${smartinit}_subsample${SUBSAMPLE}_dnoisy${dnoisy}_noisy_scale${noisy_scale}$isTest"

        # Output directory
        outdir="$RESULTS_DIR/$exp_name/"
        mkdir -p $outdir

        # Julia Command to run
        jlCmd="julia cb.jl --K_MCMC=${k_mcmc} \
          --L0_MCMC=${L0_MCMC} --L1_MCMC=${L1_MCMC} \
          --subsample=$SUBSAMPLE \
          --tau0=$TAU0 --tau1=$TAU1 \
          --RESULTS_DIR=$RESULTS_DIR --EXP_NAME=$exp_name \
          --MCMC_ITER=$MCMC_ITER --BURN=$BURN --SEED=${SEED} \
          --smartinit=$smartinit \
          --dnoisy=${dnoisy} \
          --DATA_PATH=${DATA_PATH} \
          ${otherFlags}"

        # Sync results to S3
        syncToS3="aws s3 sync $outdir $AWS_BUCKET/$exp_name --exclude '*.nfs*'"

        # Remove output files to save space on cluster
        rmOutput="rm -rf ${outdir}"


        if [[ $@ == **--testlocal** ]] || [[ $@ == **--testplots** ]]
        then
          echo $jlCmd
          $jlCmd > ${outdir}/log.txt && julia genResults.jl $RESULTS_DIR
        else
          cmd="$jlCmd > ${outdir}/log.txt && $syncToS3 && $rmOutput"
          echo $cmd
          sem -j $MAX_CORES $cmd
        fi

        echo "Results for simulation $simNumber -> $outdir"

        sleep $STAGGER_TIME
      done
    done
  done
done
